{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nCc3XZEyG3XV"
   },
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 2, Sprint 3, Module 1*\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Define ML problems\n",
    "\n",
    "You will use your portfolio project dataset for all assignments this sprint.\n",
    "\n",
    "## Assignment\n",
    "\n",
    "Complete these tasks for your project, and document your decisions.\n",
    "\n",
    "- [x] Choose your target. Which column in your tabular dataset will you predict?\n",
    "- [x] Is your problem regression or classification?\n",
    "- [x] How is your target distributed?\n",
    "    - Classification: How many classes? Are the classes imbalanced?\n",
    "    - Regression: Is the target right-skewed? If so, you may want to log transform the target.\n",
    "- [x] Choose your evaluation metric(s).\n",
    "    - Classification: Is your majority class frequency >= 50% and < 70% ? If so, you can just use accuracy if you want. Outside that range, accuracy could be misleading. What evaluation metric will you choose, in addition to or instead of accuracy?\n",
    "    - Regression: Will you use mean absolute error, root mean squared error, R^2, or other regression metrics?\n",
    "- [x] Choose which observations you will use to train, validate, and test your model.\n",
    "    - Are some observations outliers? Will you exclude them?\n",
    "    - Will you do a random split or a time-based split?\n",
    "- [x] Begin to clean and explore your data.\n",
    "- [x] Begin to choose which features, if any, to exclude. Would some features \"leak\" future information?\n",
    "\n",
    "If you haven't found a dataset yet, do that today. [Review requirements for your portfolio project](https://lambdaschool.github.io/ds/unit2) and choose your dataset.\n",
    "\n",
    "Some students worry, ***what if my model isn't â€œgoodâ€?*** Then, [produce a detailed tribute to your wrongness. That is science!](https://twitter.com/nathanwpyle/status/1176860147223867393)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. **Choose your target. Which column in your tabular dataset will you predict?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Which of the following best describes your work position?\"\n",
    "\n",
    "i.e. the type of role: BE dev, FE dev, designer, exec\n",
    "\n",
    "**Research question: are certain types of tech roles more likely to suffer from mental health issues?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. **Is your problem regression or classification?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. **How is your target distributed?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "264. But it's only 19 if you exclude job titles with fewer than 10 observations.\n",
    "\n",
    "I'd like to reduce that number to 10 or so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. **Choose your evaluation metric(s).**\n",
    "    - Classification: Is your majority class frequency >= 50% and < 70% ? If so, you can just use accuracy if you want. Outside that range, accuracy could be misleading. What evaluation metric will you choose, in addition to or instead of accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to multiclass/multilabel classification. Based on today's lecture maybe I should use ROC AUC? I could also do cross-validation. I'm open to suggestions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. **Choose which observations you will use to train, validate, and test your model.**\n",
    "    - Are some observations outliers? Will you exclude them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/validate/test split: random 80/20% train/validate split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. **Begin to clean and explore your data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing this is another notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. **Begin to choose which features, if any, to exclude. Would some features \"leak\" future information?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot I can do here. My dataset has 63 columns that each correspond to a different question asked in a survey. Not all of them are useful to my question. I'm curious how many NaNs there are per column. I also need to deal with similar replies with different answers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
